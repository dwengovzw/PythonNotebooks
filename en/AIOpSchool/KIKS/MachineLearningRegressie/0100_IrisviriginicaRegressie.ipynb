{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kiksmeisedwengougent.png\" alt=\"Banner\" width=\"1100\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">   \n",
        "<h1>REGRESSION WITH DATA ON THE IRIS VIRGINICA</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-success\">\n",
        "In this notebook, you will see how a <em>machine learning</em> system manages to find a <b>best fitting line</b> for a given collection of points. The algorithm starts with a randomly chosen line. The algorithm adjusts the coefficients in the equation of this line, based on the given data, until eventually the <b>regression line</b> is obtained.<br>",
        "First you determine the regression line with the built-in functions of the scikit-learn module. Afterwards, the algorithm is explained in case you want to know more.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Iris dataset was published in 1936 by the Brit Ronald Fischer in 'The use of multiple measurements in taxonomic problems' [1][2].<br>",
        "The dataset concerns three types of irises (*Iris setosa*, *Iris virginica* and *Iris versicolor*), 50 samples of each type.",
        "Fischer could distinguish the species from each other based on four characteristics: the length and width of the sepals and petals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kelkbladkroonblad.jpg\" alt=\"Drawing\" width=\"400\"/> <br>\n",
        "<center>Figure 1: Calyx and Corolla.</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, you only use the data on the length of the sepals and petals of the *Iris virginica*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import pandas as pd",
        "\n",
        "from sklearn.linear_model import LinearRegression",
        "from sklearn.metrics import r2_score",
        "from sklearn.metrics import mean_squared_error",
        "\n",
        "from matplotlib import animation",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h2>1. The data of the <em>Iris virginica</em></h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"images/irisvirginica.jpg\" alt=\"Drawing\" width=\"203\"/></center><br>\n",
        "<center>Figure 2: <em>Iris virginica</em> [3]</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the dataset using the `pandas` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read dataset",
        "virginica = pd.read_csv(\"data/virginica.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the data. This can be done very simply by entering the name of the table. The length of some sepals and some petals is displayed. The number of samples is easy to read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display dataset in table",
        "virginica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The relationship between the length of the calyx and the length of the petal is studied. <br> For this, the length of the petal is plotted as a function of the length of the calyx. So the length of the petal comes on the y-axis and the length of the calyx on the x-axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "For the machine learning system, the <em>length of the sepal</em> will serve as <b>input</b> and the <em>length of the petal</em> as <b>output</b>.",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = virginica[\"length sepal\"]       # use column name as index",
        "y = virginica[\"petal length\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We convert the data into NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array(x)",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h2>2. Visualizing the connection between both characteristics through a regression line</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We standardize the data and display it in a scatter plot. We calculate the correlation coefficient to see how strong the association between the two features is.<br>",
        "The regression line is then sought and drawn.<br>",
        "This regression line predicts the length of a petal for a known length of a sepals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h3>2.1 Standardize the data</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To standardize, we move on to the Z-scores of the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "More explanation about the importance of standardizing can be found in the notebook 'Standardizing'.",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = (x - np.mean(x)) / np.std(x)",
        "y = (y - np.mean(y)) / np.std(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "    <h3>2.2 Display the standardized data in a scatter plot</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# petal length vs. sepal length",
        "# sepal length comes on x-axis, petal length comes on y-axis",
        "plt.scatter(x, y, color=\"blue\", marker=\"o\")  # scatter plot",
        "\n",
        "plt.title(\"Iris virginica standardized\")",
        "plt.xlabel(\"length sepal\")          # xlabel provides description on x-axis",
        "plt.ylabel(\"petal length\")         # ylabel gives description on y-axis",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))    # to get a larger graph, so that points are more spread out",
        "# choose range so that suitable for larger and smaller leaves",
        "plt.xlim(x.min()-2, x.max()+3)",
        "plt.ylim(y.min()-2, y.max()+3)",
        "plt.scatter(x, y, color=\"blue\", marker=\"o\")",
        "\n",
        "plt.title(\"Iris virginica standardized\")",
        "plt.xlabel(\"length sepal\")",
        "plt.ylabel(\"petal length\")",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h3>2.3 Correlation between x and y?</h3>",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to what extent is there a correlation between the x and y coordinates of these points?",
        "# determine correlation coefficient (lies between -1 and 1, the closer to 0, the poorer the coherence)",
        "r = np.corrcoef(x, y)[0,1]",
        "print(\"R = \", r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Very good coherence!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h3>2.4 Regression Line</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Determine the regression line using built-in functions from the scikit-learn module, a Python module with *machine learning* algorithms. <br> In order to use such an algorithm, the *data must be presented in the desired format*. A 1D array suffices for the y-values, but the 1D array must be converted to a 2D array for the x-values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linear regression",
        "X = x[:, np.newaxis]          # provide data in desired format to ML system",
        "rechte = LinearRegression()   # rechte is determined using linear regression",
        "rechte.fit(X, y)              # this line should fit the data (X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculating R\u00b2 and the mean square deviation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# important numbers",
        "print(\"R\u00b2 for the line in relation to the data: %.3f\" % r2_score(y, line.predict(X)))",
        "print(\"Average squared deviation for the straight line with respect to the data: %.2f\"% mean_squared_error(y, rechte.predict(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show graph of scatter plot and regression line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# graph of scatter plot and regression line",
        "plt.figure(figsize=(10,8))",
        "\n",
        "plt.xlim(x.min()-2, x.max()+3)",
        "plt.ylim(y.min()-2, y.max()+3)",
        "plt.title(\"Iris virginica standardized\")",
        "plt.xlabel(\"length of sepal\")          # xlabel provides description on x-axis",
        "plt.ylabel(\"petal length\")         # ylabel gives description on y-axis",
        "\n",
        "plt.scatter(x, y, color=\"blue\", marker=\"o\")     # scatter plot",
        "plt.plot(x, rechte.predict(X), color='green')   # found regression line; substitute x-values into its equation",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the model, you can directly determine the slope of the regression line and where it intersects the y-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate slope and y-axis intersection",
        "\n",
        "# provide data in desired format",
        "x_O = np.array([0])",
        "X_O = x_O[:, np.newaxis]",
        "x_1 = np.array([1])",
        "X_1 = x_1[:, np.newaxis]",
        "\n",
        "y_O_predict = rechte.predict(X_O)",
        "y_1_predict = rechte.predict(X_1)",
        "\n",
        "print(\"The regression line intersects the y-axis at: %.3f\" % y_O_predict)",
        "print(\"The regression line has a slope of: %.3f\" % (y_1_predict - y_O_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h3>2.5 Making predictions with the model</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the model to make predictions with new data: e.g. predict the length of the petal if you know the length of a sepal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict petal length with known sepal length",
        "x_known = np.array([3])               # sepal with standardized length equal to 3",
        "X_known = x_known[:, np.newaxis]     # providing data in desired format",
        "y_predict = rechte.predict(X_gekend)   # determine petal length with model",
        "\n",
        "# graph",
        "plt.figure(figsize=(10,8))",
        "\n",
        "x_new = np.linspace(-4, 4, 67)      # draw longer straight line",
        "X_new = x_new[:, np.newaxis]       # desired format",
        "\n",
        "plt.xlim(x.min()-2, x.max()+3)",
        "plt.ylim(y.min()-2, y.max()+3)",
        "plt.title(\"Iris virginica standardized\")",
        "plt.xlabel(\"length of sepal\")",
        "plt.ylabel(\"petal length\")",
        "\n",
        "plt.scatter(x, y, color=\"blue\", marker=\"o\")     # scatter plot",
        "plt.plot(x, rechte.predict(X), color='green')   # found regression line",
        "plt.plot(x_new, straight.predict(X_new), color='yellow')   # extended found regression line",
        "plt.plot(x_known[0], y_predict[0], color=\"black\", marker=\"o\")  # predicted point",
        "\n",
        "plt.show()",
        "\n",
        "print(\"With a sepals with standardized length \" + str(x_gekend[0]) +",
        "\" is the standardized length of the petal approximately \" + str(y_predict[0]) + \".\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 2.5.1",
        "Try doing the same with a different size for the calyx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h2>3. The algorithm behind the regression line</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "    <h3>3.1 Structure of the algorithm</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Such a regression line is sought using an algorithm. Here you can see how such an algorithm is constructed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Work is still being done with the same standardized data x and y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "To find a line that fits the given data well, the ML system starts from a randomly chosen line. This is done by randomly choosing the slope and the y-intercept of this line.<br>",
        "The system is <em>trained</em> with the training set (the inputs and the corresponding outputs): For each point of the training set, it is checked how much the corresponding y-value deviates from the given y-value on the provisional straight line. The coefficients in the equation of the straight line are adjusted so that the average deviation for the entire dataset is minimal. <br>",
        "The entire training set is run through several times. Such a time is called an <em>epoch</em>. The system <em>learns</em> during these <em>attempts ('epochs')</em>.",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# training set with input x and output y",
        "print(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The system should be able to calculate the average quadratic deviation of the data points from the determined straight line.<br>To do this, the residual $y-\\hat{y}$ is calculated for each point. Here, $y$ is the given y-value and $\\hat{y}$ is the predicted value, i.e. the value obtained by substituting the given x-value into the equation of the straight line.<br> The squares of the residuals are added together. This sum divided by the number of data points is the desired error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gka(b, a, x, y):",
        "\"\"\"Calculate average squared deviation of points from straight line.\"\"\"",
        "    \n",
        "total_dev = 0",
        "n = len(x)            # number of points",
        "y_rechte = a * x + b  # y-values for certain straight line",
        "    \n",
        "    # sum of quadratic deviations at all points",
        "    for i in range(n):",
        "total_dev += (y[i] - y_line[i])**2  ",
        "    \n",
        "return total_deviation/50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As an example, you can have the average quadratic deviation calculated with respect to the x-axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# average square deviation of the training data compared to the line y = 0",
        "error = gka(0, 0, x, y)",
        "print(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "The ML system starts with a random straight line with equation <em>y = mx + q</em>. At the start of the training, <em>m</em> and <em>q</em> are randomly chosen. The number of <em>epochs</em> and the <em>learning rate</em> $\\eta$ are determined.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The algorithm will determine the coefficients of the line in such a way that the error is minimized. It does this using the **gradient descent** method.<br>",
        "After each *epoch*, the coefficients are adjusted, depending on the values of the partial derivatives and the *learning rate*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_descent(q, m, x, y, eta):",
        "\"\"\"Adjustment of parameters q and m after completed epoch with learning rate eta.\"\"\"",
        "    \n",
        "n = len(x)",
        "y_current = m * x + q      # found straight line at a certain point in process",
        "    derivative_m = 0           # declare and initialize partial derivative with respect to m",
        "afgeleide_q = 0           # declare and initialize partial derivative with respect to q",
        "    \n",
        "# calculation of the partial derivatives",
        "    for i in range(n):",
        "        derivative_m += - (2/n) * x[i] * (y[i] - y_current[i])",
        "derivative_q += - (2/n) * (y[i] - y_current[i])",
        "    \n",
        "    # adjust values of m and q",
        "m = m - eta * derivative_m",
        "    q = q - eta * derivative_q",
        "     \n",
        "# return modified values of m and q",
        "return q, m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h3>3.2 Testing the gradient descent algorithm for multiple epochs</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take 0 as the initial value for m and for q. Perform gradient descent for 3000 epochs with a learning rate of 0.01 and show the adjustments of $m$ and $q$ and the error after each *epoch*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# testing algorithm",
        "q=0",
        "m=0",
        "eta = 0.01",
        "\n",
        "for j in range(3000):",
        "fout = gka(q, m, x, y)                     # calculate average square deviation after each epoch",
        "print(q, m, fout)                          # display values q, m and fout after each epoch",
        "    q, m = gradient_descent(q, m, x, y, eta)   # adjust values of q and m after each epoch",
        "    \n",
        "print(\"The line intersects the y-axis at: %.3f\" % q)",
        "print(\"The judge has as rico: %.3f\" % m)",
        "print(\"Average squared deviation for the line with respect to the data: %.2f\"% error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the example, you can see that the number of epochs will help determine how accurately the regression line is defined. The line that has been found after, for example, 50 epochs is still very far from the intended regression line. Also note how the error progresses, as long as it continues to fall, it has not yet been minimized, the system *underfits* then.<br>",
        "In the example, you also see that there are too many epochs, at a certain point the error no longer decreases and the values are no longer adjusted. This means that the minimum has been reached.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 3.2.1",
        "You can also adjust the *learning rate* or the initial values of m and q and see what effect this has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='color: #690027;' markdown=\"1\">\n",
        "<h3>3.3 How does the error and the position of the line change during the process?</h3>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The process of determining the regression line given data (x,y) depends on the initial values of m and q, the *learning rate* (eta) and the number of times the data is run through (epochs). <br>",
        "To observe the evolution of the position of the straight line and the size of the error, the values of m, q and the error must be stored after each epoch.<br>",
        "For this purpose, three lists are created that are supplemented after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_descent_process(x, y, q, m, eta, epochs):",
        "\"\"\"Go through the process and gradually make lists of q, m and error.\"\"\"",
        "list_error = [gka(q, m, x, y)]      # declare and initialize error list",
        "list_q = [q]                       # declare and initialize list of q's",
        "list_m = [m]                       # declare and initialize list of slopes",
        "\n",
        "    # Fill in lists for each epoch",
        "    for i in range(epochs):",
        "        q, m = gradient_descent(q, m, x, y, eta)    # adjusted parameters after epoch",
        "fout = gka(q, m, x, y)                      # cost after epoch",
        "lijst_q.append(q)                           # add modified q",
        "        lijst_m.append(m)                           # add modified m",
        "        lijst_fout.append(fout)                     # add this cost",
        "\n",
        "    return [list_q, list_m, list_error]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run this algorithm for chosen *m*, *q*, *epochs* and *learning rate*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialization of m and q",
        "m = 0",
        "q = 0",
        "\n",
        "# recording the number of epochs and learning rate \u00e8ta",
        "eta = 0.01",
        "epochs = 500",
        "\n",
        "# run linear regression algorithm for choice of m, q, \u00e8ta and epochs",
        "list_q, list_m, list_error = gradient_descent_process(x, y, q, m, eta, epochs)",
        "\n",
        "# regression line",
        "print (\"Passage y-axis: %.3f\" % list_q[-1])",
        "print (\"Rico: %.3f\" % list_m[-1])",
        "\n",
        "# average squared deviation regression line",
        "print (\"Minimized error: %.2f\" % list_error[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an animation for this process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# all rights",
        "xcoord =  np.linspace(-4, 4, 67)",
        "\n",
        "ycoord = []",
        "for j in range(epochs):",
        "    y_r = lijst_m[j] * xcoord + lijst_q[j]         # Calculate y-value of all x's from xcoord for the respective line",
        "ycoord.append(y_r)",
        "ycoord = np.array(ycoord)    # type casting",
        "\n",
        "# initialize plot-window",
        "fig, ax = plt.subplots()",
        "line, = ax.plot(xcoord, ycoord[0], color=\"green\")   # plot straight line",
        "\n",
        "plt.scatter(x, y, color=\"blue\", marker=\"o\")         # scatter plot",
        "ax.axis([x.min()-2, x.max()+3, y.min()-2, y.max()+3])  # range axes",
        "\n",
        "plt.title(\"Iris virginica standardized\")",
        "plt.xlabel(\"length sepal\")          # xlabel provides description on x-axis",
        "plt.ylabel(\"petal length\")         # ylabel gives description on y-axis",
        "\n",
        "def animate(i):",
        "line.set_ydata(ycoord[i])    # update equation of the line",
        "    return line,",
        "\n",
        "plt.close()  # to temporarily close plot window, only need animation screen",
        "\n",
        "anim = animation.FuncAnimation(",
        "fig, animate, repeat=False, frames=len(ycoord))",
        "    \n",
        "HTML(anim.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# graph evolution error",
        "plt.figure(figsize=(10,8))",
        "\n",
        "plt.plot(list_error)",
        "\n",
        "plt.xlabel('epoch')",
        "plt.ylabel('average squared deviation')",
        "plt.title('Evolution of the error')",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 3.3.1",
        "Experiment yourself now. Adjust the algorithm with self-selected *m*, *q*, *epochs* and *learning rate*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "Linear regression is also covered in the notebook 'Sea level' and the notebook 'Tree height and stomata dimensions in the Amazon rainforest'.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "<h2>Reference List</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] Dua, D., & Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. <br> &nbsp; &nbsp; &nbsp; &nbsp; Irvine, CA: University of California, School of Information and Computer Science.<br>",
        "[2] Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. *Annals of Eugenics*. 7(2), 179\u2013188. <br> &nbsp; &nbsp; &nbsp; &nbsp; https://doi.org/10.1111/j.1469-1809.1936.tb02137.x<br>",
        "[3] No machine-readable author provided. Dlanglois assumed (based on copyright claims). <br> &nbsp; &nbsp; &nbsp; &nbsp;",
        "[CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0/)], via Wikimedia Commons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "<h2>With support from</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kikssteun.png\" alt=\"Banner\" width=\"1100\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/cclic.png\" alt=\"Banner\" align=\"left\" width=\"100\"/><br><br>\n",
        "Notebook KIKS, see <a href=\"http://www.aiopschool.be\">AI At School</a>, by F. Wyffels & N. Gesqui\u00e8re is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}