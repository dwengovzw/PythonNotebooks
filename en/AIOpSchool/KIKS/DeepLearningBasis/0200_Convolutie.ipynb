{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kiksmeisedwengougent.png\" alt=\"Banner\" width=\"1100\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>CONVOLUTIONS</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-success\">\n",
        "With convolutions, you can search for different features in an image. For example, you can detect edges, reduce noise in an image, or soften the contrast in an image. Convolutions are used in so-called convolutional networks.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "The <b>convolution</b> is a mathematical operation that only uses <b>addition and multiplication</b>. It basically means assigning a certain weight to a pixel and then adding the weighted values of the surrounding pixels to it.<br>",
        "In a convolution, a <b>filter</b> is 'slid' over an <b>image</b>. Both the image and the filter are matrices or tensors. The elements of the filter and the elements of the image's matrix are multiplied element-wise, and then these products are added together.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/sobelfilter.gif\" alt=\"Banner\" width=\"430\"/>\n",
        "<center>Figure 1: Convolution: the filter slides over the image [1].</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing the necessary modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SciPy module contains a toolbox, signal, for digital image processing, the toolbox contains, for example, functions that allow you to filter images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import scipy.signal",
        "from matplotlib.image import imread",
        "import scripts.helper as helper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>1. Loading Photos</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View some data from the photo of the facade of the iGent building in the Technology Park in Zwijnaarde, Ghent [2]. To do this, execute the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "igent = np.load(\"images/igent.npy\")",
        "print(igent)",
        "print(igent.shape)",
        "print(np.min(igent), np.max(igent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The loaded file is a matrix. Thus, the considered photo is a grayscale photo. View the photo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(igent, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the photo a bit larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,16))       # respect ratio",
        "plt.imshow(igent, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 1.1: Ciudad de las Artes y Ciencias, Valencia",
        "Do the same now for Cidudad de las Artes y Ciencias (City of Arts and Sciences) in Valencia. You'll find the photo `valencia.npy` in the `images` directory.<br> Complete the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valencia = np.load(\"images/valencia.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,16))",
        "plt.imshow(valencia, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In what follows, you will get to know various filters and see what their impact is on the photos.<br>",
        "You will use filters with dimension 3x3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>2. Edge Detection</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "Edge detection searches the image for pixels where the color changes drastically.",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To detect *edges*, you can, for example, use the filter $\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1   \\end{bmatrix} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To have Python perform the convolution of this chosen filter on a given image, use the function *convolve2d()*.<br>",
        "The '2d' refers to the matrices you use, matrices are 2D tensors. Both the filter and the image here are matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: iGent",
        "Try this filter on the photo of the iGent building. To do this, execute the following code cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter to detect edges",
        "rand_filter = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(rand_filter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "igent_edges = scipy.signal.convolve2d(igent, edge_filter)  # perform convolution with edge_filter on iGent photo",
        "\n",
        "# show result of convolution",
        "plt.figure(figsize=(12,16))",
        "plt.imshow(igent_randen, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "Due to the convolution that was performed, the values of the matrix no longer range from 0 to 255, but also lie outside of this range. Python will consider the highest value that appears as white and the smallest as black. All values in between are shades of gray, proportionally. <br>",
        "For more contrast, you can specify that all values from 255 should be white, and all values less than or equal to 0 black. Therefore, vmin=0, vmax=255 was added to the script.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 2.1: City of Arts and Sciences, Valencia",
        "Try out the filter on the photo of Ciudad de las Artes y Ciencias in Valencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 2.2: Stomata",
        "Do the same for the microphoto of the coffee plant. To do this, first load the photo `koffieplant.npy` which you can find in the `images` folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coffee_plant = np.load(\"images/coffee_plant.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>3. Detecting vertical and horizontal lines</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To detect *vertical lines*, for example, you use the filter $\\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1   \\end{bmatrix} $."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter to detect vertical lines",
        "vertic_filter = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: bamboo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the picture of the bamboo [3]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo = np.load(\"images/bamboo.npy\")",
        "print(bamboo.shape)",
        "plt.imshow(bamboo, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this photo, quite a few vertical lines can be seen. Test whether the filter is well chosen by running the next code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo_vertic = scipy.signal.convolve2d(bamboo, vertic_filter)",
        "\n",
        "plt.figure(figsize=(12,18))",
        "plt.subplot(1,2,1)                                        # plot with multiple images",
        "plt.imshow(bamboo, cmap=\"gray\")",
        "plt.subplot(1,2,2)",
        "plt.imshow(bamboo_vertic, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 3.1: iGent building",
        "Now detect the vertical lines in the photo of the iGent building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 3.2: Detect horizontal lines",
        "- Which filter will detect *horizontal* lines? Enter the filter in the following code cell.",
        "- Test the filter on the iGent building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>4. Detecting slanted lines</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You get two examples of filters that detect diagonal lines, each in a different direction (from top left to bottom right, or from top right to bottom left).<br>",
        "The filters are $\\begin{bmatrix} -5 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 5   \\end{bmatrix}$ and $\\begin{bmatrix} 0 & 0 & -5 \\\\ 0 & 0 & 0 \\\\ 5 & 0 & 0   \\end{bmatrix}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter to detect oblique lines",
        "schuin_filter = np.array([[-5,0,0],[0,0,0],[0,0,5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter to detect diagonal lines",
        "schuin_filter2 = np.array([[0,0,-5],[0,0,0],[5,0,0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 4.1: City of Arts and Sciences, Valencia",
        "Investigate the photo of Ciudad de las Artes y Ciencas in Valencia to determine the direction in which these filters detect slanted lines. <br>",
        "First fill in the code cell and then execute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valencia_oblique = ...........",
        "The input is missing a Dutch text to be translated to English. Please provide a correct input.",
        "\n",
        "plt.figure(figsize=(18,30))",
        "plt.subplot(...........)",
        "plt.imshow(..........., vmin=0, vmax=255, cmap=\"gray\")",
        "As there is no Dutch text provided in the input you have given, there's nothing to translate. So, the output is the same as the input.\n\nplt.subplot(...........)",
        "plt.imshow(..........., vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 4.2: stomata",
        "Apply one of these filters to the microphoto of the coffee plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>5. Soften or Sharpen Photo</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use a filter to soften or sharpen a photo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter to soften photo",
        "smooth_filter = np.array([[1, 1, 1], [1, 5, 1], [1, 1, 1]]) / 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example",
        "Soften the photo of the bamboo by running the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo_soft = scipy.signal.convolve2d(bamboo, smooth_filter)",
        "\n",
        "plt.figure(figsize=(18,24))",
        "plt.subplot(1,2,1)",
        "plt.imshow(bamboo, cmap=\"gray\")",
        "plt.subplot(1,2,2)",
        "plt.imshow(bamboo_soft, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example of two convolutions being applied consecutively",
        "In the following example, edge detection is applied to the smoothed photo of the bamboo. Execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo_soft_edges = scipy.signal.convolve2d(bamboo_soft, edge_filter)",
        "plt.figure(figsize=(9,12))",
        "plt.imshow(bamboo_soft_edges, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 5.1",
        "Check the difference in result when you perform edge detection on the photo of the bamboo itself, or only after softening.<br>",
        "Ensure that both results are shown side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 5.2: Sharpening",
        "To sharpen a photo, you can use the following filter: $\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0   \\end{bmatrix}$.<br> Enter this filter in Python with the correct instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 5.3: bamboo",
        "Sharpen the photo of the bamboo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assignment 5.4: stomata",
        "Sharpen the microphoto of the coffee plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>6. Some filters to test out</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the past, many ready-made filters have been developed by, among others, mathematicians, computer scientists and computer sciences. The advantage of these ready-made filters is that they can be directly deployed for a variety of applications in image processing. Below you will find some of these filters. Try them out on the photos from this notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter1 = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])            # emboss",
        "filter2 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9           # average",
        "filter3 = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16          # Gaussian blur",
        "filter4 = np.array([[-1, -2, -1], [-2, 12, -2], [-1, -2, -1]])      # difference between original and Gaussian blur",
        "filter5 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])            # Sobel filter edge detection",
        "filter6 = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])            # second Sobel filter edge detection",
        "filter7 = np.array([[-1, -2, -1], [-2, 12, -2], [-1, -2, -1]])      # edge detection",
        "filter8 = np.array([[1, 1, 1], [-1, -2, 1], [-1, -1, 1]])           # diagonal lines with angle of 45\u00b0",
        "filter9 = np.array([[-3, -3, 5], [-3, 0, 5], [-3, -3, 5]])          # slanting lines",
        "filter10 = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1]])            # edge detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-success\">\n",
        "Convolutions are applied in the convolutional networks. These are deep neural networks that are extremely suitable for image recognition. In the different layers of the neural network, one looks for features that become increasingly complex. In the first layer, for example, one looks for edges, in a deeper layer for an oval. To detect these features, filters are used that are slid over the image.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>7. Upload an image yourself</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the cells below, you can upload your own image as an npy file in the `images` folder as `eigen_afbeelding.npy` to apply filters to it afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(helper.upload_widget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "helper.save_npy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "own_image = np.load(\"images/own_image.npy\")",
        "plt.figure(figsize=(12,16))",
        "plt.imshow(own_picture, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "<h2>Reference List</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] Image of Rob Robinson, MLNotebook. Consulted on May 19, 2019 via https://mlnotebook.github.io.<br>",
        "[2] Photo of Hilde Christiaens, iGent building, \u00a9 UGent.<br>",
        "[3] Photo by Sean McGrath from Saint John, NB, Canada [CC BY 2.0 (https://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons.<br> &nbsp; &nbsp; &nbsp; &nbsp; Consulted on May 19, 2019 via https://nl.wikipedia.org/wiki/Bestand:Bamboo_(1466706101).jpg."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "<h2>With support from</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kikssteun.png\" alt=\"Banner\" width=\"1100\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/cclic.png\" alt=\"Banner\" align=\"left\" width=\"100\"/><br><br>\n",
        "Notebook KIKS, see <a href=\"http://www.aiopschool.be\">AI at School</a>, by F. Wyffels & N. Gesqui\u00e8re is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}