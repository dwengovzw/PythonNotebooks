{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kiksmeisedwengougent.png\" alt=\"Banner\" width=\"1100\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>CONVOLUTIONS</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-success\">\n",
        "Convolutions can be used to look for different features in an image. They can be used to detect edges, reduce noise or soften contrast in an image. Convolutions are used in so-called convolutional networks.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "<b>Convolution</b> is a mathematical operation that only uses <b>addition and multiplication</b>. Essentially, one assigns a certain weight to a pixel and adds the weighted values of the surrounding pixels.",
        "Convolution involves 'sliding' a <b>filter</b> over an <b>image</b>. Both the image and the filter are matrices or tensors. The elements of the filter and the elements of the matrix of the image are multiplied element by element and then these products are added.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/sobelfilter.gif\" alt=\"Banner\" width=\"430\"/>\n",
        "<center>Figure 1: Convolution: the filter slides over the image [1].</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importeer de nodige modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The SciPy module contains a toolbox *signal*, for digital image processing. This toolbox contains for instance functions for filtering images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "The input provided does not contain any Dutch text to translate to English. Therefore, the returned input is: \n\nimport scipy.signal",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>1. Loading pictures</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at some data from the picture of the facade of the iGent building in the Technology Park in Zwijnaarde, Ghent [2]. To do so, execute the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "igent = np.load(\"images/igent.npy\")",
        "print(igent)",
        "print(igent.shape)",
        "print(np.min(igent), np.max(igent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The loaded file contains a matrix. It's a grayscale image, therefore. Take a look at the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(igent, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Increase the displayed image size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,16))       # respect ratio",
        "plt.imshow(igent, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1.1: City of Arts and Sciences, Valencia",
        "Now do the same for Cidudad de las Artes y Ciencias (City of Arts and Sciences) in Valencia. You will find the image `valencia.npy` in the `images` folder.<br> Fill in the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valencia = np.load(\"images/valencia.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,16))",
        "plt.imshow(valencia, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following, you are going to learn about different filters and see what impact they have on the pictures.<br>",
        "You will use a filter size of 3x3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>2. Detect edges</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "Edge detection searches for pixels in the image where the color changes dramatically.",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To detect *edges* you can for instance use the filter $\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1   \\end{bmatrix} $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To have Python perform the convolution of this chosen filter on a given image, you use the function *convolve2d()*.<br>",
        "The '2d' refers to the matrices you are using, matrices are 2D tensors. Here, both the filter and the image are matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: iGent",
        "Try this filter on the picture of the iGhent building. To execute this, run the following code cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# edge detection filter",
        "edge_filter = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(edge_filter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "igent_edges = scipy.signal.convolve2d(igent, edge_filter)  # perform convolution with edge_filter on picture iGent",
        "\n",
        "# show result of convolution",
        "plt.figure(figsize=(12,16))",
        "plt.imshow(igent_edges, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-info\">\n",
        "Due to the convolution performed, the values of the matrix no longer go from 0 to 255, but also exceed this range. Python will consider the largest value to be white and the smallest to be black. All values in between are grey values, proportional to the black and white. <br>",
        "For more contrast, you can specify that all values above 255 should be white, and all values less than or equal to 0 should be black. Therefore, in the script vmin=0, vmax=255. was added.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2.1: City of Arts and Sciences, Valencia",
        "Try the filter on the photo of the City of Arts and Sciences in Valencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2.2: stomata",
        "Do the same for the micro picture of the coffee plant. First load the picture `koffieplant.npy` that you find in the folder `images`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coffee_plant = np.load(\"images/coffee_plant.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>3. Detect vertical and horizontal lines</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To detect *vertical lines* you can for example use the filter $\\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1   \\end{bmatrix} $."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vertical line detection filter",
        "vertic_filter = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: bamboo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at the picture of bamboo [3]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo = np.load(\"images/bamboo.npy\")",
        "print(bamboo.shape)",
        "plt.imshow(bamboo, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In deze afbeelding kun je veel verticale lijnen zien. Test of het filter goed is gekozen door de volgende codecel uit te voeren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo_vertic = scipy.signal.convolve2d(bamboo, vertic_filter)",
        "\n",
        "plt.figure(figsize=(12,18))",
        "plt.subplot(1,2,1)                                        # plot multiple images",
        "plt.imshow(bamboo, cmap=\"gray\")",
        "plt.subplot(1,2,2)",
        "plt.imshow(bamboo_vertic, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 3.1: iGent Building",
        "Now detect the vertical lines in the picture of the iGent building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 3.2: detect horizontal lines",
        "- Which filter will detect *horizontal* lines? Enter the filter in the next code cell.",
        "- Test the filter on the iGent building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>4. Detect slanted lines</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You get two examples of filters that detect slanted lines, each in a different direction (from top left to bottom right, or from top right to bottom left).<br>",
        "The filters are $\\begin{bmatrix} -5 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 5   \\end{bmatrix}$ and $\\begin{bmatrix} 0 & 0 & -5 \\\\ 0 & 0 & 0 \\\\ 5 & 0 & 0   \\end{bmatrix}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# slanted line detection filter",
        "slanted_filter = np.array([[-5,0,0],[0,0,0],[0,0,5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# slanted line detection filter",
        "slanted_filter2 = np.array([[0,0,-5],[0,0,0],[5,0,0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 4.1: City of Arts and Sciences, Valencia",
        "Examine the picture from Ciudad de las Artes y Ciencas in Valencia to see in which direction these filters detect slanted lines.<br>",
        "First complete the code cell and then execute it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "valencia_slanted= ...........",
        "valencia_slanted2 = ...........",
        "\n",
        "plt.figure(figsize=(18,30))",
        "plt.subplot(...........)",
        "plt.imshow(..........., vmin=0, vmax=255, cmap=\"gray\")",
        "plt.subplot(...........)",
        "plt.imshow(..........., vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 4.2: stomata",
        "Apply one of these filters to the microphotograph of the coffee plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>5. Smooth or sharpen picture</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use a filter to smooth or sharpen a photo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# picture smoothing filter",
        "smooth_filter = np.array([[1, 1, 1], [1, 5, 1], [1, 1, 1]]) / 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sorry, but I'm unable to respond without having any Dutch text to translate. However, I would be glad to assist if you provide some input to translate.",
        "Smooth the image of the bamboo by running the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo_smooth = scipy.signal.convolve2d(bamboo, smooth_filter)",
        "\n",
        "plt.figure(figsize=(18,24))",
        "plt.subplot(1,2,1)",
        "plt.imshow(bamboo, cmap=\"gray\")",
        "plt.subplot(1,2,2)",
        "plt.imshow(bamboo_smooth, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example of two convolutions applied sequentially",
        "In the following example, edge detection is applied to the smoothed image of the bamboo. Execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bamboo_smooth_edges = scipy.signal.convolve2d(bamboo_smooth, edge_filter)",
        "plt.figure(figsize=(9,12))",
        "plt.imshow(bamboo_smooth_edges, vmin=0, vmax=255, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 5.1",
        "See the difference in results if you perform edge detection on the photo of the bamboo itself, or after smoothing.<br>",
        "Sorry, there's no visible input here. Please provide the text that needs to be translated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 5.2: Sharpen",
        "To sharpen a photo, you can use the following filter: $\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0   \\end{bmatrix}$.<br> Enter this filter in Python with the appropriate instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 5.3: bamboo",
        "Sharpen the image of the bamboo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 5.4: stomata",
        "Sharpen the microphoto of the coffee plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <font color=#690027 markdown=\"1\">\n",
        "<h1>6. Some filters to test</h1>",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the past, many ready-made filters have been developed by mathematicians, computer scientists and others. The benefit of these pre-made filters is that they can be immediately utilized for many applications in image processing. Below are some of these filters. Try them out yourself on the pictures in this notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter1 = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])            # emboss",
        "filter2 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9           # average",
        "filter3 = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16          # Gaussian blur",
        "filter4 = np.array([[-1, -2, -1], [-2, 12, -2], [-1, -2, -1]])      # difference between original and Gaussian blur",
        "filter5 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])            # Sobel filter edge detection",
        "filter6 = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])            # second Sobel filter edge detection",
        "filter7 = np.array([[-1, -2, -1], [-2, 12, -2], [-1, -2, -1]])      # edge detection",
        "filter8 = np.array([[1, 1, 1], [-1, -2, 1], [-1, -1, 1]])           # slanted lines with angle of 45\u00b0",
        "filter9 = np.array([[-3, -3, 5], [-3, 0, 5], [-3, -3, 5]])          # slanted lines",
        "filter10 = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1]])            # edge detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-box alert-success\">\n",
        "Convolutions are used in convolutional networks. These are deep neural networks that are highly suitable for image recognition. In the various layers of the neural network, one looks for features that become increasingly complex. For example, in the first layer one looks for edges, in a deeper layer for an oval. To detect these features, filters are used that slide over the image.",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "    <h2>References</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] Image of Rob Robinson, MLNotebook. Accessed on May 19, 2019 via https://mlnotebook.github.io.<br>",
        "[2] Picture of Hilde Christiaens, iGent building, \u00a9 UGent.<br>",
        "[3] Picture of Sean McGrath from Saint John, NB, Canada [CC BY 2.0 (https://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons.<br> &nbsp; &nbsp; &nbsp; &nbsp; Accessed on May 19, 2019 via https://nl.wikipedia.org/wiki/Bestand:Bamboo_(1466706101).jpg."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "<h2>With the support of</h2>",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/kikssteun.png\" alt=\"Banner\" width=\"1100\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/cclic.png\" alt=\"Banner\" align=\"left\" width=\"100\"/><br><br>\n",
        "Notebook KIKS, see <a href=\"http://www.aiopschool.be\">AI At School</a>, by F. wyffels & N. Gesqui\u00e8re is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International licence</a>."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}