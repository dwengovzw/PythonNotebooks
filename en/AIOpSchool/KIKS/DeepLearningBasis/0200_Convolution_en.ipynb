{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kiksmeisedwengougent.png\" alt=\"Banner\" width=\"1100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>CONVOLUTIONS</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-success\">\n",
    "Convolutions can be used to look for different features in an image. They can be used to detect edges, reduce noise or soften contrast in an image. Convolutions are used in so-called convolutional networks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    <b>Convolution</b> is a mathematical operation that only uses <b>addition and multiplication</b>. Essentially, one gives a pixel a certain weight and adds weighted values of the surrounding pixels.\n",
    "    Convolution involves 'sliding' a <b>filter</b> over an <b>image</b>. Both the image and the filter are matrices or tensors. The elements of the filter and the elements of the matrix of the image are multiplied element by element and then these products are added.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sobelfilter.gif\" alt=\"Banner\" width=\"430\"/>\n",
    "<center>Figure 1: Convolution: the filter slides over the image [1].</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SciPy module contains a toolbox *signal*, for digital image processing. This toolbox contains for instance functions for filtering images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>1. Loading pictures</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some data from the picture of the facade of the iGent building in the Technology Park in Zwijnaarde, Ghent [2]. To do so, execute the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igent = np.load(\"images/igent.npy\")\n",
    "print(igent)\n",
    "print(igent.shape)\n",
    "print(np.min(igent), np.max(igent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded file contains a matrix. It is therefore a grayscale image. Look at the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(igent, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the displayed image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,16))       # respect ratio\n",
    "plt.imshow(igent, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Ciudad de las Artes y Ciencias, Valencia\n",
    "Now do the same for Cidudad de las Artes y Ciencias (City of Arts and Sciences) in Valencia. You will find the image `valencia.npy` in the `images` folder.<br> Fill in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valencia = np.load(\"images/valencia.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,16))       \n",
    "plt.imshow(valencia, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, you are going to learn about different filters and see what impact they have on the pictures.<br>\n",
    "You will use a filter size of 3x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>2. Detect edges</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "Edge detection looks for pixels in the image where the colour changes dramatically.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect *edges* you can for instance use the filter $\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1   \\end{bmatrix} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have Python perform the convolution of this chosen filter on a given image, you use the function *convolve2d()*.<br>\n",
    "The '2d' refers to the matrices you are using, matrices are 2D tensors. Here, both the filter and the image are matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: iGent\n",
    "Try this filter on the picture of the iGhent building. To do so, execute the following code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge detection filter\n",
    "edge_filter = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igent_edges = scipy.signal.convolve2d(igent, edge_filter)  # perform convolution with edge_filter on picture iGent\n",
    "\n",
    "# show result of convolution \n",
    "plt.figure(figsize=(12,16))\n",
    "plt.imshow(igent_edges, vmin=0, vmax=255, cmap=\"gray\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "    Due to the convolution performed, the values of the matrix no longer go from 0 to 255, but they are also beyond that. Python will consider the largest value to be white and the smallest to be black. All values in between are grey values, proportionate tot the black and white. <br>\n",
    "For more contrast, you can specify that all values above 255 should be white, and all values less than or equal to 0 should be black. Therefore, in the script vmin=0, vmax=255. was added.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Ciudad de las Artes y Ciencias, Valencia\n",
    "Try the filter on the photo of the City of Arts and Sciences in Valencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: stomata\n",
    "Do the same for the micro picture of the coffee plant. First load the picture `koffieplant.npy` that you find in the folder `images`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koffieplant = np.load(\"images/koffieplant.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>3. Detect vertical and horizontal lines</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TTo detect *vertical lines* you can for example use the filter $\\begin{bmatrix} -1 & 0 & 1 \\\\ -1 & 0 & 1 \\\\ -1 & 0 & 1   \\end{bmatrix} $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertical line detection filter\n",
    "vertic_filter = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: bamboo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the picture of bamboo [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamboo = np.load(\"images/bamboe.npy\")\n",
    "print(bamboo.shape)\n",
    "plt.imshow(bamboo, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this picture you can see a lot of vertical lines. Test if the filter is well chosen by running the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamboo_vertic = scipy.signal.convolve2d(bamboo, vertic_filter)\n",
    "\n",
    "plt.figure(figsize=(12,18))\n",
    "plt.subplot(1,2,1)                                        # plot multiple images\n",
    "plt.imshow(bamboo, cmap=\"gray\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(bamboo_vertic, vmin=0, vmax=255, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: iGent building\n",
    "Now detect the vertical lines on the picture of the iGent building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: detect horizontal lines\n",
    "- Which filter will detect *horizontal* lines? Enter the filter in the next code cell.\n",
    "- Test the filter on the iGent building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>4. Detect slanted lines</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get two examples of filters that detect slanted lines, each in a different direction (from top left to bottom right, or from top right to bottom left).<br>\n",
    "The filters are $\\begin{bmatrix} -5 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 5   \\end{bmatrix}$ en $\\begin{bmatrix} 0 & 0 & -5 \\\\ 0 & 0 & 0 \\\\ 5 & 0 & 0   \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slanted line detection filter\n",
    "slanted_filter = np.array([[-5,0,0],[0,0,0],[0,0,5]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slanted line detection filter\n",
    "slanted_filter2 = np.array([[0,0,-5],[0,0,0],[5,0,0]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Ciudad de las Artes y Ciencas, Valencia\n",
    "Examine the picture from Ciudad de las Artes y Ciencas in Valencia to see in which direction these filters detect slanted lines.<br>\n",
    "First complete the code cell and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valencia_slanted= ...........\n",
    "valencia_slanted2 = ...........\n",
    "\n",
    "plt.figure(figsize=(18,30))\n",
    "plt.subplot(...........)\n",
    "plt.imshow(..........., vmin=0, vmax=255, cmap=\"gray\")\n",
    "plt.subplot(...........)\n",
    "plt.imshow(..........., vmin=0, vmax=255, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: stomata\n",
    "Apply one of these filters to the microphotograph of the coffee plant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>5. Smoothen or sharpen picture</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a filter to smoothen or sharpen a photo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picture smoothening filter\n",
    "smooth_filter = np.array([[1, 1, 1], [1, 5, 1], [1, 1, 1]]) / 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Smooth the picture of the bamboo by executing the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamboo_smooth = scipy.signal.convolve2d(bamboo, smooth_filter)\n",
    "\n",
    "plt.figure(figsize=(18,24))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(bamboo, cmap=\"gray\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(bamboo_smooth, vmin=0, vmax=255, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of two convolutions applied sequentially\n",
    "In the following example, edge detection is applied to the smoothened image of the bamboo. Execute the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamboo_smooth_edges = scipy.signal.convolve2d(bamboo_smooth, edge_filter)\n",
    "plt.figure(figsize=(9,12))\n",
    "plt.imshow(bamboo_smooth_edges, vmin=0, vmax=255, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1\n",
    "See the difference in results if you carry out the edge detection on the photo of the bamboo itself, or after smoothening.<br>\n",
    "Make sure that both results are shown next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: sharpen\n",
    "To sharpen a photo, you can use the following filter: $\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0   \\end{bmatrix}$.<br> Enter this filter in Python with the appropriate instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.3: bamboo\n",
    "Sharpen the picture of the bamboo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.4: stomata\n",
    "Sharpen the microphoto of the coffee plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">\n",
    "        <h1>6. Some filters to test</h1> \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past, many ready-made filters have been developed by mathematicians, computer scientists and others. The advantage of these ready-made filters is that they can be used immediately for many applications in image processing. Below are some of these filters. Try them out yourself on the pictures in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])            # emboss\n",
    "filter2 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9           # average\n",
    "filter3 = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16          # Gaussian blur\n",
    "filter4 = np.array([[-1, -2, -1], [-2, 12, -2], [-1, -2, -1]])      # difference between original and Gaussian blur\n",
    "filter5 = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])            # Sobel filter edge detection\n",
    "filter6 = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])            # second Sobel filter edge detection\n",
    "filter7 = np.array([[-1, -2, -1], [-2, 12, -2], [-1, -2, -1]])      # edge detection\n",
    "filter8 = np.array([[1, 1, 1], [-1, -2, 1], [-1, -1, 1]])           # slanted lines with angle of 45°\n",
    "filter9 = np.array([[-3, -3, 5], [-3, 0, 5], [-3, -3, 5]])          # slanted lines\n",
    "filter10 = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1]])            # edge detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-success\">\n",
    "Convolutions are used in convolutional networks. These are deep neural networks that are extremely suitable for image recognition. In the various layers of the neural network, one looks for characteristics that become increasingly complex. For example, in the first layer one looks for edges, in a deeper layer for an oval. In order to detect these characteristics, filters are used that are sliding over the image.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>References</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Image of Rob Robinson, MLNotebook. Accessed on 19 mei 2019 via https://mlnotebook.github.io.<br>\n",
    "[2] Picture of Hilde Christiaens, iGent building, © UGent.<br>\n",
    "[3] Picture of Sean McGrath from Saint John, NB, Canada [CC BY 2.0 (https://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons.<br> &nbsp; &nbsp; &nbsp; &nbsp;  Accessed on 19 mei 2019 via https://nl.wikipedia.org/wiki/Bestand:Bamboo_(1466706101).jpg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>With the support of</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kikssteun.png\" alt=\"Banner\" width=\"1100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cclic.png\" alt=\"Banner\" align=\"left\" width=\"100\"/><br><br>\n",
    "Notebook KIKS, see <a href=\"http://www.aiopschool.be\">AI Op School</a>, of F. wyffels & N. Gesquière, is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International licence</a>. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
