{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kiksmeisedwengougent.png\" alt=\"Banner\" width=\"1100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">   \n",
    "<h1>DEMARCATION LINE STOMATA ON SUNLIT AND SHADED LEAVES</h1>    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-success\">\n",
    "In this notebook, you will determine a straight line that separates the sunned and shaded leaves (approximately). For this, you will use machine learning techniques, such as gradient descent.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krappa or crabwood is a rapidly growing tree species that is common in the Amazon region. Mature specimens can have a diameter of more than a meter and can be more than 40 meters high. <br>The high-quality wood is used for making furniture, flooring, masts ... A fever-reducing agent is extracted from the bark. Oil for medicinal applications, including the treatment of skin diseases and tetanus, and as a repellent for insects, is produced from the seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"images/andirobaamazonica.jpg\" alt=\"Drawing\" width=\"200\"/></td>\n",
    "<td> <img src=\"images/crabwoodtree.jpg\" alt=\"Drawing\" width=\"236\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "Photos: Mauroguanandi [Public domain] [2] and P. S. Sena [CC BY-SA 4.0] [3].</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some climate models predict a rise in temperature and a decrease in rainfall in the coming decades, it is important to know how these trees adapt to changing conditions. <br>Scientists Camargo and Marenco conducted research in the Amazon rainforest [1].<br>In addition to the influence of seasonal rainfall, they also examined stomatal characteristics of leaves under sunny and under shaded conditions. <br> For this, a number of plants, grown in the shade, were moved to full sunlight for 60 days. Another group of plants was kept in the shade. <br> The characteristics of the stomata were measured on prints of the leaves made with transparent nail polish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">   \n",
    "<h2>1. Reading the data</h2>    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset using the `pandas` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stomata = pd.read_csv(\"data/schaduwzon.csv\", header=\"infer\")  # table to be read has a heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">   \n",
    "<h2>2. Step by step in search of the dividing line</h2>    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the researchers, you plot the stomatal density against the stomatal length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the previous notebook, the standardized data is used for x$_{1}$ and x$_{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label data\n",
    "x1 = stomata[\"stomatal length\"]          # feature: length\n",
    "x2 = stomata[\"stomatal density\"]       # attribute: density\n",
    "x1 = np.array(x1)          # feature: length\n",
    "x2 = np.array(x2)          # feature: density\n",
    "# standardize\n",
    "x1 = (x1 - np.mean(x1)) / np.std(x1)\n",
    "x2 = (x2 - np.mean(x2)) / np.std(x2)\n",
    "# labels\n",
    "y = stomata[\"milieu\"]            # labels: second column of the original table\n",
    "y = np.array(y)\n",
    "y = np.where(y == \"zon\", 1, 0)     # make labels numeric, sun:1, shadow:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1, x2), axis = 1)    # correct formatone_colum\n",
    "n = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((one_column, X), axis = 1)   # Add 1 at every point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training set with input X(x1, x2) and output y\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">   \n",
    "<h3>2.1 Structure of the algorithm</h3>    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a dividing line is searched for with an algorithm. Here you can see how such an algorithm is structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-info\">\n",
    "The ML system is a neural network without a hidden layer and with the activation function being the sigmoid function.<br> The error function used is binary cross entropy.<br>To find a line that separates the two classes, the ML system starts with a randomly chosen line. This is done by randomly choosing the slope and the y-intercept of this line.<br>The system is <em>trained</em> with the training set (the inputs and the corresponding labels): for each point of the training set, it is determined how much the error is. The coefficients in the equation of the line are adjusted until the error is minimal. <br>The entire training set is run through a number of times. Such a time is called an <em>epoch</em>. The system <em>learns</em> during these <em>attempts ('epochs')</em>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network first makes a linear combination of the input with the weights.<br> The **activation function** then works on this result. In this neural network, it's *sigmoid*. For each data point, the sigmoid function returns a value between 0 and 1. This value indicates how certain the system is that the point belongs to the class with label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    \"The prediction is a value that indicates how certain the point belongs to the class with label 1.\"    \n",
    "    \n",
    "    z = np.dot(features, weights.T)\n",
    "    prediction = sigmoid(z)    \n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system should be able to calculate the error after each epoch. <br>For this purpose, the residual $y-\\hat{y}$ is calculated for each point. Here, $y$ is the given y-value and $\\hat{y}$ is the predicted value, i.e., the value obtained by substituting the given x-value into the equation of the line.<br> The squares of the residuals are added together. This sum divided by the number of data points is the error sought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bc(features, labels, weights):\n",
    "    \"\"\"Calculate error binary crossentropy.\"\"\"    \n",
    "    n = len(y)            # number of points\n",
    "    predictions = predict(features, weights)            # current prediction    \n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = - labels * np.log(predictions)\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1 - labels) * np.log(1-predictions)    \n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost + class2_cost\n",
    "    #Take the average cost\n",
    "    cost = cost.mean()\n",
    "    \n",
    "    return cost\n",
    "\n",
    "# def loss(h, y):\n",
    "#    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(features, labels, weights, eta):\n",
    "    \"\"\"Adjustment of parameters q and m after completed epoch with learning rate eta.\"\"\"    \n",
    "    \n",
    "    n = len(labels)                                 # number of points is number of values in list of labels y\n",
    "    predictions = predict(features, weights)        # view current predictions     \n",
    "\n",
    "    # Transpose features X \n",
    "    # So we can multiply with the matrix.# Returns a (3,1) matrix (predictions - labels)\n",
    "    \n",
    "    # calculating the partial derivatives\n",
    "    gradient = np.dot(features.T, (predictions - labels))    \n",
    "    gradient = gradient / n    \n",
    "    \n",
    "    # adjust values weights    \n",
    "    weights = weights - eta *gradient  \n",
    "    # return customized weights\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">   \n",
    "<h3>2.2 Testing the gradient descent algorithm for multiple epochs</h3>    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take (0; 1; 0.2) as the initial value for the *weights*. Perform gradient descent for 200 epochs with a learning rate of 0.01, displaying the adjustments to the *weights* and the error after each *epoch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing algorithm\n",
    "w = np.array([0, 1, 0.2])\n",
    "eta = 0.01\n",
    "\n",
    "for j in range(200):\n",
    "    fout = bc(X,y,w)                       # calculate binary crossentropy after each epoch\n",
    "    print(j, w, fout)                      # display weights and error values after each epoch\n",
    "    w = gradient_descent(X, y, w, eta)     # adjust weights values after each epoch    \n",
    "\n",
    "print(\"The line intersects the y-axis at: %.3f\" % (-w[0]/w[2]))\n",
    "print(\"The line has as slope: %.3f\" % (-w[1]/w[2]))\n",
    "print(\"Binary crossentropy for the line w.r.t. the data: %.4f\" % fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, you can see that the number of epochs will help determine how accurately the dividing line is determined. The line that was found after e.g. 20 epochs is still very far from the intended dividing line. Also look at how the error develops; as long as it continues to decrease in absolute value, it has not been minimized yet, the system is then *underfit*. Apparently the error does increase again. Perhaps the *learning rate* is too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <font color=#690027 markdown=\"1\">   \n",
    "<h3>2.3 How do the error and the position of the line change during the process?</h3>    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_process(features, labels, weights, eta, epochs):\n",
    "    \"\"\"Go through the process and gradually make lists of q, m and error.\"\"\"\n",
    "    list_error = [bc(features, labels, weights)]      # Declare and initialize error list\n",
    "    list_weights = [weights]                          # declare and initialize list of weights    \n",
    "\n",
    "    # Fill lists for each epoch\n",
    "    for i in range(epochs):\n",
    "        weights = gradient_descent(features, labels, weights, eta)    # modified parameters after epoch\n",
    "        error = bc(features, labels, weights)                        # cost after epoch\n",
    "        list_weights.append(weights)                           # add adjusted q\n",
    "        list_fout.append(fout)                           # add this error\n",
    "\n",
    "    return [list_weights, list_error]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through the process for chosen initial values for the weights, chosen *learning rate* and chosen number of *epochs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of the weights\n",
    "w = np.array([0, 1, 0.2])\n",
    "\n",
    "# recording the number of epochs and learning rate èta\n",
    "eta = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# running linear regression algorithm for choice of weights, èta and epochs\n",
    "list_weights, list_error = gradient_descent_process(X, y, w, eta, epochs)\n",
    "\n",
    "# dividing line\n",
    "print (\"Passage y-axis: %.3f\" % (-list_weights[-1][0]/list_weights[-1][2]))\n",
    "print (\"Slope: %.3f\" % (-list_weights[-1][1]/list_weights[-1][2]))\n",
    "\n",
    "# average square deviation regression line\n",
    "print (\"Minimized error: %.4f\" %  list_error[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all straight lines\n",
    "xcoord = np.linspace(-2, 2, 30)\n",
    "\n",
    "ycoord = []\n",
    "for j in range(epochs):    \n",
    "    y_r = (-list_weights[j][1]/list_weights[j][2]) * xcoord + (-list_weights[j][0]/list_weights[j][2]) # calculate y-value from all x's from xcoord for the respective line    \n",
    "    ycoord.append(y_r)\n",
    "ycoord = np.array(ycoord)    # type casting\n",
    "\n",
    "# initialize plot window\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot(xcoord, ycoord[0], color=\"green\")   # plot line\n",
    "\n",
    "ax.axis([x1.min()-1,x1.max()+1,x2.min()-1,x2.max()+1])  # axis range\n",
    "plt.title(\"Amazon sun-shadow standardized\")\n",
    "plt.xlabel(\"stomata length\")              # xlabel provides a description on the x-axis\n",
    "plt.ylabel(\"stomatal density\")         # ylabel gives a description on the y-axis\n",
    "plt.scatter(x1[:25], x2[:25], color=\"lightgreen\", marker=\"o\", label=\"sun\")      # sun's first 25 (label 1)\n",
    "plt.scatter(x1[25:], x2[25:], color=\"darkgreen\", marker=\"o\", label=\"shadow\")   # shadow are the next 25 (label 0)\n",
    "\n",
    "def animate(i):\n",
    "    line.set_ydata(ycoord[i])    # update the equation of the line\n",
    "\n",
    "plt.close()  # to temporarily close the plot window, only animation screen needed\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, repeat=False, frames=len(ycoord))    \n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph evolution error\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(list_error)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('binary cross entropy')\n",
    "plt.title('Evolution of the error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the *learning rate* and the number of *epochs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-warning\">\n",
    "In the following notebook, you perform the classification using an existing Python module, namely scikit-learn.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h2>Reference List</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Camargo, Miguel Angelo Branco, & Marenco, Ricardo Antonio. (2012). Growth, leaf and stomatal traits of crabwood (Carapa guianensis Aubl.)<br> &nbsp; &nbsp; &nbsp; &nbsp; in central Amazonia. Revista Árvore, 36(1), 07-16. https://dx.doi.org/10.1590/S0100-67622012000100002 and via e-mail.<br>[2] Mauroguanandi [Public domain]. https://commons.wikimedia.org/wiki/File:Andirobaamazonica.jpg. <br> &nbsp; &nbsp; &nbsp; &nbsp; Consulted on August 13, 2019 via Wikimedia Commons. <br>[3] Sena, P. S. https://commons.wikimedia.org/wiki/File:Crabwood_tree.JPG. [CC BY-SA 4.0] Accessed on August 13, 2019 via Wikimedia Commons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h2>With support from</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kikssteun.png\" alt=\"Banner\" width=\"1100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cclic.png\" alt=\"Banner\" align=\"left\" width=\"100\"/><br><br>\n",
    "Notebook KIKS, see <a href=\"http://www.aiopschool.be\">AI At School</a>, by F. wyffels & N. Gesquière, is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
