{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logodwengo.png\" alt=\"logodwengo\" style=\"width:200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h1>VAN BLAD NAAR LABEL: STOMATADETECTIE</h1> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-box alert-success\">\n",
    "In deze notebook train en test je jouw eigen diep neuraal netwerk om stomata te detecteren. De methodologie is dezelfde zoals uitgelegd in de paper van Meeus et al. [1].\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/stomatamethodologie.png\" alt=\"methodologie\" style=\"width:600px;\"/>\n",
    "\n",
    "Zoals hierboven geïllustreerd glijdt er een venster over je microfoto (A). Dit *sliding window* verdeelt je foto dus in kleine overlappende vlakken of patches (B) van 120 op 120 pixels. Er is een diep neuraal netwerk (VGG19) getraind om deze patches te labelen (C). Positief gelabelde patches van een microfoto  worden geclusterd (D),  wat uitmondt in de detectie (E). Deze detectie is afhankelijk van de drempelwaarde, de *threshold*, die je koos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodige modules importeren\n",
    "\n",
    "Je start met het inladen van enkele Python-modules:\n",
    "\n",
    "- [PIL](https://pillow.readthedocs.io/en/stable/): een handige Python-module om te werken met beelden;\n",
    "- [NumPy](https://numpy.org): de basismodule om wetenschappelijke bewerkingen in Python uit te voeren;\n",
    "- [sklearn](https://scikit-learn.org/stable/): de scikit-learn module voor machinaal leren, in het bijzonder voor de functionaliteit van het clusteren;\n",
    "- [os](https://docs.python.org/3/library/os.html): een Python-module voor functionaliteiten die afhankelijk zijn van het besturingssysteem, bv. lezen, schrijven en bestanden oplijsten;\n",
    "- [Matplotlib](https://matplotlib.org): een Python-module om grafieken te maken.\n",
    "\n",
    "Een diep neuraal netwerk bestaat uit meerdere lagen die aaneengeschakeld zijn. De Python-module Keras voorziet bouwblokken om een neuraal netwerk op te bouwen. In de achterliggende code zijn de nodige functionaliteiten vervat. Voor het rekenen met tensoren en andere rekenkundige bewerkingen doet Keras zelf een beroep op het platform TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens laad je meerdere [Keras](https://keras.io/getting_started/intro_to_keras_for_researchers/)-modules in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Convolution2D, Conv2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import get_file\n",
    "from keras.utils import layer_utils\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# limiteren GPU VRAM\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>1. Dataset</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om een *deep learning*-model te kunnen trainen, heb je data nodig. Zoals eerder vermeld, zal het deep learning-model stomata detecteren op vierkante patches van 120 op 120 pixels. Dat komt omdat het getraind wordt met zo'n patches. Om een robuust model te bekomen, moeten zowel positieve als negatieve voorbeelden aan het systeem worden gepresenteerd. Positieve voorbeelden zijn voorbeelden met een stoma, negatieve voorbeelden zijn voorbeelden zonder stoma.\n",
    "\n",
    "De data worden opgesplitst in drie delen:\n",
    "- De trainingset, dit zijn de data die gebruikt worden om de gewichten, de *weights*, van het (diep) neuraal netwerk aan te passen;\n",
    "- De validatieset, dit zijn de data waarmee wordt gekeken hoe goed het leerproces vordert en om de hyperparameters van het model fijner af te stellen;\n",
    "- De testset, dit zijn de data die je na de training aan het systeem geeft om het ontwikkelde model te testen.\n",
    "\n",
    "Deze notebook bevat de training en de validering van het *deep learning*-systeem voor stomatadetectie, en een kleine dataset die beperkt is tot *Carapa procera* en geschikt is voor didactische doeleinden. Hierdoor zijn ook de computationele noden binnen de perken gehouden (een volledige training met meerdere plantensoorten (zie de paper) vergt meer tijd en geduld).\n",
    "\n",
    "Na de training zou het model in principe moeten getest worden op de testset. In deze notebook wordt die test beperkt tot één afbeelding. Dit omwille van de tijd en omdat dit volstaat voor het doeleinde van deze notebook: demonstreren hoe een convolutioneel neuraal netwerk voor stomatadetectie opgebouwd, getraind, gevalideerd en tot slot ingezet wordt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download en unzip eerst de dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/record/3902280/files/data.zip\n",
    "!unzip 'data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./data/training/\"\n",
    "val_dir = \"./data/validation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De trainings- en validatiedata bevatten patches van 120 op 120 pixels. Een positief gelabelde patch vertoont een stoma:\n",
    "\n",
    "<img src=\"images/carapapositief.jpg\" width=\"120\" />\n",
    "    \n",
    "Een negatief gelabelde patch van *Carapa procera* heeft geen stoma (tenzij misschien een deel ervan):\n",
    "\n",
    "<img src=\"images/carapanegatief.jpg\" width=\"120\" />\n",
    "\n",
    "Om zulke patches te bekomen, moet je beschikken over geannoteerde microfoto's (microfoto's waarvan je de coördinaat kent van het midden van de aanwezige stoma). De patches kunnen dan, gebaseerd op deze coördinaten, uitgesneden worden door middel van de [*crop*-functie](https://pillow.readthedocs.io/en/stable/reference/Image.html) van PIL of nog eenvoudiger door gebruik te maken van [*matrix slicing*](https://numpy.org/doc/stable/reference/arrays.indexing.html) in NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het aantal elementen in de dataset wordt vergroot door middel van *data augmentation*. De preprocessor [ImageDataGenerator](https://keras.io/api/preprocessing/image/#imagedatagenerator-class) definieert de *data augmentation* die toegepast zal worden op de dataset. Hier bestaat die uit willekeurige rotaties, en horizontale en verticale *flips* van de patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=180, horizontal_flip=True, vertical_flip=True, rescale=1/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behalve het bepalen van de *data augmentation* die zal worden toegepast, gebruik je de ImageDataGenerator ook om enkele zaken vast te leggen: \n",
    "- de afmetingen van de patches (120 x 120 pixels); \n",
    "- de kleurenmodus (grijswaarden of rgb);\n",
    "- de grootte van de batch (dit is het aantal samples dat gebruikt wordt in een epoch van de training, dus in elke trainingiteratie);\n",
    "- het classificatietype van de te volbrengen taak (hier binaire classificatie: een patch krijgt ofwel een positief ofwel een negatief label);\n",
    "- of de data geshuffeld moet worden of niet;\n",
    "- de *seed*, het startpunt, van de willekeurige getalgenerator. \n",
    "\n",
    "Tot slot voorzie je een pad naar de map met de trainingdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"./data/training/\",\n",
    "    target_size=(120, 120),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=53\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook voor de validatie stel je een ImageDataGenerator in. Deze definieer je met dezelfde eigenschappen als diegene voor de training maar zonder *data augmentation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r\"./data/validation/\",\n",
    "        target_size=(120, 120),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>2. Netwerkarchitectuur met nodige parameters</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vertrekt van het convolutioneel neuraal netwerk van het [VGG19-model](https://arxiv.org/abs/1409.1556) waar je twee *dense layers* aan toevoegt. <br>\n",
    "De convolutionele neurale lagen zijn voorgetraind op [ImageNet](https://ieeexplore.ieee.org/abstract/document/5206848). Bijgevolg moeten enkel de *dense layers* nog getraind worden.<br>\n",
    "De voorgetrainde gewichten van het convnet download je van Keras via het sleutelwoord \"imagenet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_dense_neurons = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We starten van VGG19\n",
    "from keras.applications import VGG19\n",
    "\n",
    "# We starten met de convolutionele lagen van VGG19 met voorgetrainde gewichten op Imagenet\n",
    "vgg19_base = VGG19(weights='imagenet',include_top=False,input_shape=(120,120,3))\n",
    "x = vgg19_base.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# We voegen onze eigen classificatielagen toe\n",
    "x = Dense(2*number_dense_neurons,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(number_dense_neurons,activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# We voegen een output laag toe\n",
    "x = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=vgg19_base.input, outputs=x)\n",
    "\n",
    "# We stellen in dat we de (voorgetrainde) VGG19 lagen niet trainen\n",
    "for layer in vgg19_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Hoe ziet het netwerk er uit\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>3. Train het model en sla het op</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De parameters worden geoptimaliseerd door beroep te doen op de optimalisatiefunctie [Adam](https://arxiv.org/pdf/1412.6980.pdf); hiervoor werd de *learning rate* gefinetuned en uiteindelijk op 0.000005 afgesteld. Tot slot leg je de *loss* en de *metrics* voor training en validatie vast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.000005\n",
    "# Initialiseer Stochastic Gradient Descent met momentum, learning rate om te finetunen\n",
    "opt = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "# Bepaal de loss en metrics voor training en validatie\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training gebeurt door middel van de functie *fit()* gedurende 50 epochs. Merk op dat de architectuur op zo'n manier werd geconfigureerd dat enkel de gewichten van de *dense layers* aangepast worden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu ben je toe aan de volgende stap. Het netwerk is immers getraind en kan nu gebruikt worden.<br>\n",
    "Om het AI-systeem te kunnen gebruiken, moet je de parameters van het model opslaan. Dit kan je doen door de instructie *model.save(path)* met *path* het pad naar het bestand waarin je de parameters wilt bewaren.<br>\n",
    "Bovendien geeft de functie *fit()* een *history* object terug. Dit object omvat de vooruitgang van de training en van de validatie over de verschillende epochs. Bijgevolg is dit nuttig om het trainingsproces in het oog te houden, bijvoorbeeld om de resultaten van verschillende instellingen van de hyperparameters, zoals de *learning rate*, het aantal *epochs* en de grootte van de *batches*, te vergelijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bewaar the Carapa procera deep learning model\n",
    "model.save('my_carapa_procera_model')\n",
    "\n",
    "# Geef de prestaties voor training en validatie weer\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>4. Laad het deep learning-model in</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu heb je een eerste deep learning-model voor stomatadetectie bij de *Carapa procera* getraind. Dit model is opgeslagen als het object *model*.<br> Als je van een gesaved deep learning model wilt vertrekken, dan haal je het op vanuit de file door de instructie *model = load_model(path_to_model)* uit te voeren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>5. Beeld- en detectieparameters</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het model kan enkel stomata detecteren op afbeeldingen van 120 op 120 pixels. Daarom moet een aangeboden afbeelding eerst verdeeld worden in patches. Het model maakt daarvoor gebruik van een werkwijze met een *sliding window*.<br>\n",
    "Hoewel deze methode niet de meest (computationeel) efficiënte is, is ze zeer gemakkelijk te begrijpen. Het venster is 120 op 120 pixels groot en verschuift telkens met een stap van 10 pixels.<br> Je start door je afbeelding in te laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_image = './data/Carapa_procero_demo.jpg' # Je kan een andere Carapa procero microfoto gebruiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(demo_image)\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "image = np.array(image) # Conversie naar Numpy array\n",
    "ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 10\n",
    "patch_size = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook het aantal slides dat uitgevoerd wordt, maakt deel uit van de detectieparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_x_shifts = (np.shape(image)[0] - patch_size) // shift\n",
    "no_y_shifts = (np.shape(image)[1] - patch_size) // shift\n",
    "print(\"We doen \"+str(no_x_shifts*no_y_shifts)+\" verschuivingen. Bijgevolg wordt het deep learning model op \"+str(no_x_shifts*no_y_shifts)+\" patches toegepast.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>6. Classificatie met het deep learning-model</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu alle vensters geïdentificeerd zijn, kan het deep learning-model in actie treden. Je bewerkstelligt dit door de functie *predict()* te aanroepen. Weliswaar moet je de gebruikte afbeelding eerst converteren (omzetten naar het verwachte formaat) en normaliseren (elementen krijgen waarden van 0 t.e.m. 1).<br> \n",
    "De output van het deep learning model is een getal tussen 0 en 1 dat weergeeft hoe zeker het model is dat de afbeelding een stoma vertoont. Daarom moet je ook een drempelwaarde, *threshold*, vastleggen vanaf dewelke de output als een positieve classificatie wordt geaccepteerd. Hoe hoger deze threshold, hoe strenger het systeem zal handelen bij het detecteren van de stomata. Als de threshold echter te hoog is, zal het systeem niet in staat zijn om ook maar één stoma te detecteren. De threshold hieronder is dezelfde als in de paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stomata = []\n",
    "offset = patch_size // 2\n",
    "for x in np.arange(no_x_shifts + 1):\n",
    "    for y in np.arange(no_y_shifts + 1):\n",
    "        # Midden van het venster\n",
    "        x_c = x * shift + offset\n",
    "        y_c = y * shift + offset\n",
    "        \n",
    "        # Uitknippen van het venster en omzetten naar verwachte formaat vooraleer toepassing van het deep learning model\n",
    "        patch = image[x_c - offset:x_c + offset, y_c - offset:y_c + offset, :]\n",
    "        patch = patch.astype('float32')\n",
    "        patch /= 255\n",
    "        \n",
    "        # Het model toepassen om de detectie te doen\n",
    "        y_model = model.predict(np.expand_dims(patch, axis=0))\n",
    "\n",
    "        # Stoma indien de output van het model boven de threshold ligt \n",
    "        if y_model[0] > threshold:\n",
    "            stomata.append([x_c, y_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>7. Clustering van de gedetecteerde stomata</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle positief gelabelde patches worden geclusterd door middel van *mean shift clustering*. Deze techniek groepeert naburige (of zelfs overlappende) positief gelabelde patches waaruit de coördinaat van de effectieve stoma afgeleid wordt. Hiervoor kun je beroep doen op de module [MeanShift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html) die beschikbaar is in [scikit-learn](https://scikit-learn.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = patch_size // 2\n",
    "\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(stomata)\n",
    "stomata = np.array([[x[1], x[0]] for x in ms.cluster_centers_]) # cluster_centers_ is inverted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='color: #690027;' markdown=\"1\">\n",
    "    <h2>8. Grafische voorstelling van de resultaten</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.imshow(image)\n",
    "ax.plot(stomata[:,0], stomata[:,1], 'xr', alpha=0.75, markeredgewidth=3, markersize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referentielijst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Meeus, S., Van den Bulcke, J., & wyffels, F. (2020). From leaf to label: A robust automated workflow for stomata detection. *Ecology and evolution 10*(17),<br>&nbsp; &nbsp; &nbsp; &nbsp; 9178-9191. [doi:10.1002/ece3.6571](https://doi.org/10.1002/ece3.6571) <br>\n",
    "[2]  Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. *arXiv preprint*. [arXiv:1409.1556](https://arxiv.org/abs/1409.1556) <br>\n",
    "[3]  Deng, J., et al. (2009). Imagenet: A large-scale hierarchical image database. *IEEE conference on computer vision and pattern recognition*. [IEEE](https://ieeexplore.ieee.org/abstract/document/5206848) <br>\n",
    "[4] Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. *arXiv preprint*. [arXiv:1412.6980](https://arxiv.org/pdf/1412.6980.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cclic.png\" alt=\"Banner\" align=\"left\" style=\"width:100px;\"/><br><br>\n",
    "Notebook KIKS, zie <a href=\"http://www.aiopschool.be\">AI Op School</a>,  van F. wyffels voor Dwengo vzw, in licentie gegeven volgens een <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</a>. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
